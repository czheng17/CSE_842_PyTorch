{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warmup project\n",
    "## author: Chen Zheng\n",
    "## 10/05/2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  [(1, 3.499828461376741), (2, 6.837807871826528), (3, 9.076002535161544), (4, 12.419121052667485), (5, 15.766450341854696)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "dataset = []\n",
    "\n",
    "ground_truth_w = 3\n",
    "dataset = []\n",
    "for i in range(1,6):\n",
    "    x = i\n",
    "    y = ground_truth_w * x + random.random() ## y = w*x + b\n",
    "    dataset.append((x,y))\n",
    "print('dataset: ', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup 1:\n",
    "\n",
    "input: a set of pairs $[(x_1,y_1), (x_2, y_2), ..., (x_n, y_n)]$\n",
    "\n",
    "output: Find the weight w that minimizes $f(w)$. $f(w)$ is the squared mean error function (object function) where $f(w) = \\frac{1}{n}\\sum_{i=1}^n(w*x_i - y)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_f_(w):\n",
    "    res = 0\n",
    "    for x, y in dataset:\n",
    "        res += (w*x - y)**2\n",
    "    return res / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_f_(w):\n",
    "    res = 0\n",
    "    for x, y in dataset:\n",
    "        res += 2 * (w*x - y) * x\n",
    "    return res / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  w:  0.06916487509218314  val:  108.83875237446264\n",
      "iter:  50  w:  2.132873428256286  val:  11.870976420972644\n",
      "iter:  100  w:  2.8114378787263985  val:  1.387316763281907\n",
      "iter:  150  w:  3.0345554854910937  val:  0.2538771361731187\n",
      "iter:  200  w:  3.1071099446928563  val:  0.13201126561586968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w = 0\n",
    "lr = 0.001\n",
    "for iter in range(200):\n",
    "    val = object_f_(w)\n",
    "    gradient = gradient_f_(w)\n",
    "    w = w - lr*gradient\n",
    "    if iter % 50 == 0:\n",
    "        print('iter: ', iter, ' w: ', w, ' val: ', val)\n",
    "    # print('iter: ', iter, ' w: ', w, ' val: ', val)\n",
    "print('iter: ', 200, ' w: ', w, ' val: ', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup 2:\n",
    "\n",
    "Upgrade the the level of the difficulty:\n",
    "\n",
    "- First chage: w from a 1-D tesor to 5-D tensor.\n",
    "\n",
    "- Second change: randomly generate 100 data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ground_truth_w = np.array([1, 2, 3, 2, 1]) ### change from w = 1 to w = [1, 2, 3, 2, 1]\n",
    "dim = len(ground_truth_w)\n",
    "dataset = []\n",
    "for i in range(100):\n",
    "    x = np.random.randn(dim)\n",
    "    y = ground_truth_w.dot(x) + np.random.randn() ## y = w.dot(x) + b\n",
    "    dataset.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_f_(w):\n",
    "    res = 0\n",
    "    for x, y in dataset:\n",
    "        res += (w.dot(x) - y)**2 # matrix operation\n",
    "    return res / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_f_(w):\n",
    "    res = 0\n",
    "    for x, y in dataset:\n",
    "        res += 2 * (w.dot(x) - y) * x # matrix operation\n",
    "    return res / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iter = 3000 ## how about 1000? 2000? In fact, You will find the surprise after more than 2000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  w:  [0.00141762 0.0059876  0.00510628 0.00336429 0.00302314]  val:  20.34661522386116\n",
      "iter:  200  w:  [0.24917855 0.92693206 0.86661234 0.56051896 0.46088986]  val:  9.2563434271883\n",
      "iter:  400  w:  [0.43746682 1.45744173 1.47645011 0.9431638  0.7130934 ]  val:  4.674189995149578\n",
      "iter:  600  w:  [0.58053317 1.76055387 1.91013173 1.21063659 0.84758678]  val:  2.6893093149728795\n",
      "iter:  800  w:  [0.68918699 1.93181745 2.21989255 1.40053195 0.91567979]  val:  1.786229725182306\n",
      "iter:  1000  w:  [0.77165002 2.02708762 2.44205516 1.53713879 0.9470855 ]  val:  1.355767754486614\n",
      "iter:  1200  w:  [0.8341854  2.07890704 2.60200709 1.63647732 0.95883812]  val:  1.142109672430849\n",
      "iter:  1400  w:  [0.88156746 2.1061527  2.71758221 1.70933649 0.96056763]  val:  1.0325435721766787\n",
      "iter:  1600  w:  [0.9174357  2.11971076 2.80136937 1.76312905 0.95761072]  val:  0.9749473940356802\n",
      "iter:  1800  w:  [0.94456337 2.12581007 2.8622967  1.80304229 0.95283883]  val:  0.944120856818746\n",
      "iter:  2000  w:  [0.96506214 2.1279767  2.90672455 1.83276501 0.94772667]  val:  0.9274115738141114\n",
      "iter:  2200  w:  [0.9805385  2.12817723 2.9392032  1.85495608 0.94297265]  val:  0.9182748497113431\n",
      "iter:  2400  w:  [0.99221335 2.12748524 2.963001   1.87155323 0.93885572]  val:  0.9132488902533384\n",
      "iter:  2600  w:  [1.00101358 2.12646838 2.98047431 1.88398083 0.93543793]  val:  0.9104729315858766\n",
      "iter:  2800  w:  [1.00764209 2.12541171 2.99332786 1.89329279 0.93267738]  val:  0.9089354562179811\n",
      "iter:  3000  w:  [1.01260978 2.12445026 3.00275831 1.90024259 0.93049914]  val:  0.908085448411208\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(dim)  ### change from w = 0 to w = [0,0,0,0,0]\n",
    "lr = 0.001\n",
    "for iter in range(total_iter):\n",
    "    val = object_f_(w)\n",
    "    gradient = gradient_f_(w)\n",
    "    w = w - lr*gradient\n",
    "    if iter % 200 == 0:\n",
    "        print('iter: ', iter, ' w: ', w, ' val: ', val)\n",
    "    # print('iter: ', iter, ' w: ', w, ' val: ', val)\n",
    "print('iter: ', total_iter, ' w: ', w, ' val: ', val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
